# ==============================================================================
# youtube.py - YouTube Download & Search Handler
# ==============================================================================
# This file handles all YouTube-related operations:
# - Searching for videos/audio
# - Downloading YouTube content using yt-dlp
# - Managing YouTube cookies for age-restricted content
# - Caching search results for better performance
# - Validating YouTube URLs
# ==============================================================================

import os
import re
import yt_dlp
import random
import asyncio
import aiohttp
from pathlib import Path
from typing import Optional, Union

from pyrogram import enums, types
from py_yt import Playlist, VideosSearch
from HasiiMusic import logger
from HasiiMusic.helpers import Track, utils


class YouTube:
    def __init__(self):
        """Initialize YouTube handler with configuration and caching."""
        self.base = "https://www.youtube.com/watch?v="  # Base YouTube URL
        self.cookies = []  # List of available cookie files
        self.checked = False  # Whether cookies directory has been checked
        self.warned = False  # Whether missing cookies warning has been shown

        # Regular expression to match YouTube URLs (videos, shorts, playlists)
        self.regex = re.compile(
            r"(https?://)?(www\.|m\.|music\.)?"
            r"(youtube\.com/(watch\?v=|shorts/|playlist\?list=)|youtu\.be/)"
            r"([A-Za-z0-9_-]{11}|PL[A-Za-z0-9_-]+)([&?][^\s]*)?"
        )

        # Cache search results to reduce API calls (10 minute TTL)
        self.search_cache = {}  # {"query_video": (result, timestamp)}
        self.cache_time = {}  # Deprecated, using tuple in search_cache instead

    def get_cookies(self):
        if not self.checked:
            for file in os.listdir("HasiiMusic/cookies"):
                if file.endswith(".txt"):
                    self.cookies.append(file)
            self.checked = True
        if not self.cookies:
            if not self.warned:
                self.warned = True
                logger.warning("Cookies are missing; downloads might fail.")
            return None
        return f"HasiiMusic/cookies/{random.choice(self.cookies)}"

    async def save_cookies(self, urls: list[str]) -> None:
        logger.info("üç™ Saving cookies from urls...")
        for url in urls:
            path = f"HasiiMusic/cookies/cookie{random.randint(10000, 99999)}.txt"
            link = url.replace("me/", "me/raw/")
            async with aiohttp.ClientSession() as session:
                async with session.get(link) as resp:
                    with open(path, "wb") as fw:
                        fw.write(await resp.read())
        logger.info("‚úÖ Cookies saved.")

    def valid(self, url: str) -> bool:
        return bool(re.match(self.regex, url))

    def url(self, message_1: types.Message) -> Union[str, None]:
        messages = [message_1]
        link = None
        if message_1.reply_to_message:
            messages.append(message_1.reply_to_message)

        for message in messages:
            text = message.text or message.caption or ""

            if message.entities:
                for entity in message.entities:
                    if entity.type == enums.MessageEntityType.URL:
                        link = text[entity.offset: entity.offset +
                                    entity.length]
                        break

            if message.caption_entities:
                for entity in message.caption_entities:
                    if entity.type == enums.MessageEntityType.TEXT_LINK:
                        link = entity.url
                        break

        if link:
            return link.split("&si")[0].split("?si")[0]
        return None

    async def search(self, query: str, m_id: int, video: bool = False) -> Track | None:
        # Check cache first (10-minute TTL)
        cache_key = f"{query}_{video}"
        current_time = asyncio.get_event_loop().time()

        if cache_key in self.search_cache:
            cached_result, cache_timestamp = self.search_cache[cache_key]
            if current_time - cache_timestamp < 600:  # 10 minutes
                # Return cached result with new message_id
                cached_result.message_id = m_id
                return cached_result

        _search = VideosSearch(query, limit=1)
        results = await _search.next()
        if results and results["result"]:
            data = results["result"][0]
            duration = data.get("duration")
            is_live = duration is None or duration == "LIVE"

            track = Track(
                id=data.get("id"),
                channel_name=data.get("channel", {}).get("name"),
                duration=duration if not is_live else "LIVE",
                duration_sec=0 if is_live else utils.to_seconds(duration),
                message_id=m_id,
                title=data.get("title")[:25],
                thumbnail=data.get(
                    "thumbnails", [{}])[-1].get("url").split("?")[0],
                url=data.get("link"),
                view_count=data.get("viewCount", {}).get("short"),
                video=video,
                is_live=is_live,
            )

            # Cache the result
            self.search_cache[cache_key] = (track, current_time)
            # Limit cache size to 100 entries
            if len(self.search_cache) > 100:
                oldest_key = min(self.search_cache.keys(),
                                 key=lambda k: self.search_cache[k][1])
                del self.search_cache[oldest_key]

            return track
        return None

    async def playlist(self, limit: int, user: str, url: str, video: bool) -> list[Track]:
        try:
            plist = await Playlist.get(url)
            tracks = []

            # Check if plist has videos
            if not plist or "videos" not in plist or not plist["videos"]:
                return []

            for data in plist["videos"][:limit]:
                try:
                    # Get thumbnail safely
                    thumbnails = data.get("thumbnails", [])
                    thumbnail_url = ""
                    if thumbnails and len(thumbnails) > 0:
                        thumbnail_url = thumbnails[-1].get(
                            "url", "").split("?")[0]

                    # Get link safely
                    link = data.get("link", "")
                    if "&list=" in link:
                        link = link.split("&list=")[0]

                    track = Track(
                        id=data.get("id", ""),
                        channel_name=data.get("channel", {}).get("name", ""),
                        duration=data.get("duration", "0:00"),
                        duration_sec=utils.to_seconds(
                            data.get("duration", "0:00")),
                        title=(data.get("title", "Unknown")[:25]),
                        thumbnail=thumbnail_url,
                        url=link,
                        user=user,
                        view_count="",
                        video=video,
                    )
                    tracks.append(track)
                except Exception as e:
                    # Skip individual track errors
                    continue

            return tracks
        except KeyError as e:
            # Handle YouTube API structure changes
            raise Exception(
                f"Failed to parse playlist. YouTube may have changed their structure.")
        except Exception as e:
            # Re-raise other exceptions
            raise

    async def download(self, video_id: str, video: bool = False, is_live: bool = False) -> Optional[str]:
        url = self.base + video_id

        # For live streams, extract the direct stream URL using yt-dlp with cookies
        if is_live:
            cookie = self.get_cookies()
            ydl_opts = {
                "quiet": True,
                "no_warnings": True,
                "cookiefile": cookie,
                # For live streams: use specific format codes that PyTgCalls can handle
                # Video formats: 96 (1080p), 95 (720p), 94 (480p) + 140 (audio)
                # Force direct URL extraction instead of manifest
                "format": "95+140/94+140/96+140/best" if video else "bestaudio/best",
                "format_sort": ["proto:https"],  # Prefer HTTPS
            }

            def _extract_url():
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    try:
                        info = ydl.extract_info(url, download=False)
                        return info.get("url") or info.get("manifest_url")
                    except yt_dlp.utils.ExtractorError as ex:
                        error_msg = str(ex)
                        if "Sign in to confirm" in error_msg or "bot" in error_msg.lower():
                            logger.error(
                                "YouTube bot detection triggered. Please update cookies.")
                        elif "not available" in error_msg.lower():
                            logger.error(
                                "Video format not available or region-blocked.")
                        else:
                            logger.error(
                                "Live stream URL extraction failed: %s", ex)
                        return None
                    except yt_dlp.utils.DownloadError as ex:
                        error_msg = str(ex)
                        if "failed to load cookies" in error_msg.lower() or "netscape format" in error_msg.lower():
                            logger.error(
                                "‚ùå Corrupted cookie file detected for live stream, removing: %s", cookie)
                            # Remove corrupted cookie
                            if cookie and cookie in self.cookies:
                                self.cookies.remove(cookie)
                            try:
                                os.remove(f"HasiiMusic/cookies/{cookie}")
                            except:
                                pass
                        else:
                            logger.error(
                                "Unexpected error during live stream extraction: %s", ex)
                        return None
                    except Exception as ex:
                        logger.error(
                            "Unexpected error during live stream extraction: %s", ex)
                        return None

            stream_url = await asyncio.to_thread(_extract_url)
            return stream_url if stream_url else url

        ext = "mp4" if video else "webm"
        filename = f"downloads/{video_id}.{ext}"

        if Path(filename).exists():
            return filename

        cookie = self.get_cookies()
        base_opts = {
            "outtmpl": "downloads/%(id)s.%(ext)s",
            "quiet": True,
            "noplaylist": True,
            "geo_bypass": True,
            "no_warnings": True,
            "overwrites": False,
            "nocheckcertificate": True,
            "cookiefile": cookie,
            "continuedl": True,
            "noprogress": True,
            "concurrent_fragment_downloads": 16,
            "http_chunk_size": 1048576,  # 1MB chunks
            "socket_timeout": 15,
            "retries": 1,
            "fragment_retries": 1,
            "ignoreerrors": True,
        }

        if video:
            ydl_opts = {
                **base_opts,
                "format": "(bestvideo[height<=?720][width<=?1280][ext=mp4])+(bestaudio)",
                "merge_output_format": "mp4",
            }
        else:
            # High-quality audio: Opus codec in WebM container for best quality
            ydl_opts = {
                **base_opts,
                "format": "bestaudio[ext=webm][acodec=opus]/bestaudio[acodec=opus]/bestaudio",
                "postprocessors": [],  # No post-processing to preserve original quality
            }

        def _download():
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                try:
                    ydl.download([url])
                    # Check if file was actually downloaded (handle .part rename issues)
                    if not Path(filename).exists():
                        # Wait briefly for filesystem operations to complete
                        import time
                        time.sleep(0.5)
                        if Path(filename).exists():
                            return filename
                        
                        # Try to find .part file and rename it
                        part_file = Path(f"{filename}.part")
                        if part_file.exists():
                            try:
                                import shutil
                                shutil.move(str(part_file), filename)
                                logger.info(f"‚úÖ Renamed {part_file} to {filename}")
                                return filename
                            except Exception as rename_ex:
                                logger.error(f"‚ùå Failed to rename .part file: {rename_ex}")
                                return None
                        else:
                            logger.error(f"‚ùå Download completed but file not found: {filename}")
                            return None
                    return filename
                except yt_dlp.utils.ExtractorError as ex:
                    error_msg = str(ex)
                    if "Sign in to confirm" in error_msg or "bot" in error_msg.lower():
                        logger.error(
                            "‚ùå YouTube bot detection: Please update cookies or wait before retrying.")
                    elif "not available" in error_msg.lower():
                        logger.error(
                            "‚ùå Video not available: May be region-blocked or private.")
                    elif "age" in error_msg.lower():
                        logger.error(
                            "‚ùå Age-restricted video: Cookies required.")
                    else:
                        logger.error("‚ùå YouTube extraction failed: %s", ex)
                    if cookie and cookie in self.cookies:
                        self.cookies.remove(cookie)
                    return None
                except yt_dlp.utils.DownloadError as ex:
                    error_msg = str(ex)
                    if "failed to load cookies" in error_msg.lower() or "netscape format" in error_msg.lower():
                        logger.error(
                            "‚ùå Corrupted cookie file detected, removing: %s", cookie)
                        # Remove corrupted cookie from list and filesystem
                        if cookie and cookie in self.cookies:
                            self.cookies.remove(cookie)
                        try:
                            os.remove(f"HasiiMusic/cookies/{cookie}")
                        except:
                            pass
                    else:
                        logger.error("‚ùå Download error: %s", ex)
                        if cookie and cookie in self.cookies:
                            self.cookies.remove(cookie)
                    return None
                except Exception as ex:
                    logger.error("‚ùå Unexpected download error: %s", ex)
                    return None
            return filename

        return await asyncio.to_thread(_download)
